{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating derived features...\n",
      "Derived features created.\n",
      "\n",
      "Data shapes after split: TrainVal(17760), Test(4440)\n",
      "\n",
      "Starting RandomizedSearchCV (30 iterations) using CPU...\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "\n",
      "==================================================\n",
      "RandomizedSearchCV Results:\n",
      "==================================================\n",
      "Best tuned hyperparameters found: {'random_strength': 0.5, 'learning_rate': 0.01, 'l2_leaf_reg': 1, 'depth': 8, 'colsample_bylevel': 0.9, 'border_count': 128, 'bagging_temperature': 2.0}\n",
      "Best CV ROC AUC score from RandomizedSearchCV: 0.7186\n",
      "==================================================\n",
      "\n",
      "Parameters for Final Model Training: {'random_strength': 0.5, 'learning_rate': 0.01, 'l2_leaf_reg': 1, 'depth': 8, 'colsample_bylevel': 0.9, 'border_count': 128, 'bagging_temperature': 2.0}\n",
      "\n",
      "Training final tuned model with early stopping on test set using CPU...\n",
      "0:\ttest: 0.6835084\tbest: 0.6835084 (0)\ttotal: 10.9ms\tremaining: 21.8s\n",
      "100:\ttest: 0.7143633\tbest: 0.7143633 (100)\ttotal: 987ms\tremaining: 18.6s\n",
      "200:\ttest: 0.7205572\tbest: 0.7205627 (198)\ttotal: 1.98s\tremaining: 17.7s\n",
      "300:\ttest: 0.7233573\tbest: 0.7234466 (298)\ttotal: 2.99s\tremaining: 16.9s\n",
      "400:\ttest: 0.7255667\tbest: 0.7255771 (399)\ttotal: 3.99s\tremaining: 15.9s\n",
      "500:\ttest: 0.7270521\tbest: 0.7270766 (499)\ttotal: 4.99s\tremaining: 14.9s\n",
      "600:\ttest: 0.7281897\tbest: 0.7282067 (599)\ttotal: 5.99s\tremaining: 14s\n",
      "700:\ttest: 0.7287057\tbest: 0.7288721 (693)\ttotal: 6.99s\tremaining: 13s\n",
      "800:\ttest: 0.7293372\tbest: 0.7293372 (800)\ttotal: 8s\tremaining: 12s\n",
      "900:\ttest: 0.7291612\tbest: 0.7293568 (853)\ttotal: 9.01s\tremaining: 11s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7293568497\n",
      "bestIteration = 853\n",
      "\n",
      "Shrink model to first 854 iterations.\n",
      "\n",
      "Best iteration found by early stopping for the final model: 853\n",
      "\n",
      "==================================================\n",
      "Feature Importance Analysis:\n",
      "==================================================\n",
      "\n",
      "Top 20 Feature Importances:\n",
      "                    Feature Id  Importances\n",
      "0                 data_channel     8.305122\n",
      "1                      weekday     6.414523\n",
      "2                   kw_avg_avg     4.889358\n",
      "3    self_reference_min_shares     4.435461\n",
      "4                   kw_min_avg     3.745014\n",
      "5                   kw_max_avg     3.704458\n",
      "6   self_reference_avg_sharess     3.526870\n",
      "7                       LDA_00     3.111236\n",
      "8                       LDA_01     2.809678\n",
      "9              n_unique_tokens     2.628968\n",
      "10   feat_content_to_img_ratio     2.393039\n",
      "11                  kw_max_max     2.369842\n",
      "12                      LDA_02     2.158613\n",
      "13                      LDA_04     2.119484\n",
      "14    n_non_stop_unique_tokens     2.056811\n",
      "15                  kw_min_min     1.994357\n",
      "16   self_reference_max_shares     1.936791\n",
      "17                      LDA_03     1.895182\n",
      "18                  kw_max_min     1.833939\n",
      "19                  kw_avg_min     1.813908\n",
      "\n",
      "Feature importances saved to 'feature_importances_with_derived_cpu_original_params.csv'\n",
      "\n",
      "Consider reviewing feature importances. Low importance features might be removed,\n",
      "and high importance features could inspire new derived features in the next iteration.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Tuned Model with Derived Features - FINAL HOLD-OUT TEST PERFORMANCE (CPU-trained):\n",
      "==================================================\n",
      "Accuracy : 0.6694\n",
      "F1 Score : 0.6667\n",
      "ROC AUC  : 0.7294\n",
      "Composite : 0.6885\n",
      "==================================================\n",
      "\n",
      "Saving the trained model to 'catboost_final_model_cpu.cbm'...\n",
      "Model saved successfully.\n",
      "\n",
      "Total script execution time: 0h 12m 1s\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) # CatBoost can be verbose with warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from catboost import CatBoostClassifier\n",
    "import time # Add time library\n",
    "import os # Add os library\n",
    "\n",
    "# Define the path to save the trained model\n",
    "MODEL_FILE_PATH = 'catboost_final_model_cpu.cbm'\n",
    "\n",
    "# Start measuring total execution time\n",
    "start_time = time.time()\n",
    "\n",
    "# 1) 데이터 로드\n",
    "try:\n",
    "    df = pd.read_csv('train.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'train.csv' not found. Please ensure the file is in the correct directory.\")\n",
    "    exit()\n",
    "\n",
    "X = df.drop(columns=['id', 'shares', 'y'])\n",
    "y = df['y']\n",
    "\n",
    "# *** 파생변수 생성 시작 ***\n",
    "print(\"Creating derived features...\")\n",
    "epsilon = 1e-6 # 0으로 나누기 방지\n",
    "\n",
    "# 1. 콘텐츠 길이 대비 링크 수 비율\n",
    "if 'n_tokens_content' in X.columns and 'num_hrefs' in X.columns:\n",
    "    X['feat_content_to_href_ratio'] = X['n_tokens_content'] / (X['num_hrefs'] + epsilon)\n",
    "else:\n",
    "    print(\"Warning: Columns for 'feat_content_to_href_ratio' not found.\")\n",
    "\n",
    "# 2. 콘텐츠 길이 대비 이미지 수 비율\n",
    "if 'n_tokens_content' in X.columns and 'num_imgs' in X.columns:\n",
    "    X['feat_content_to_img_ratio'] = X['n_tokens_content'] / (X['num_imgs'] + epsilon)\n",
    "else:\n",
    "    print(\"Warning: Columns for 'feat_content_to_img_ratio' not found.\")\n",
    "\n",
    "# 3. 평균 키워드 공유 수 편차\n",
    "if 'kw_avg_max' in X.columns and 'kw_avg_min' in X.columns:\n",
    "    X['feat_kw_avg_spread'] = X['kw_avg_max'] - X['kw_avg_min']\n",
    "else:\n",
    "    print(\"Warning: Columns for 'feat_kw_avg_spread' not found.\")\n",
    "\n",
    "# 4. 전반적인 주관성 가중 감성\n",
    "if 'global_subjectivity' in X.columns and 'global_sentiment_polarity' in X.columns:\n",
    "    X['feat_global_sentiment_strength'] = X['global_subjectivity'] * X['global_sentiment_polarity']\n",
    "else:\n",
    "    print(\"Warning: Columns for 'feat_global_sentiment_strength' not found.\")\n",
    "\n",
    "# 5. 제목의 주관성 가중 감성\n",
    "if 'title_subjectivity' in X.columns and 'title_sentiment_polarity' in X.columns:\n",
    "    X['feat_title_sentiment_strength'] = X['title_subjectivity'] * X['title_sentiment_polarity']\n",
    "else:\n",
    "    print(\"Warning: Columns for 'feat_title_sentiment_strength' not found.\")\n",
    "\n",
    "# LDA 관련 변수들\n",
    "lda_cols = ['LDA_00', 'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04']\n",
    "if all(col in X.columns for col in lda_cols):\n",
    "    # 6. LDA 주제 값 중 최댓값\n",
    "    X['feat_lda_max_value'] = X[lda_cols].max(axis=1)\n",
    "    # 7. LDA 주제 값들의 표준편차\n",
    "    X['feat_lda_std_dev'] = X[lda_cols].std(axis=1)\n",
    "else:\n",
    "    print(f\"Warning: Not all LDA columns ({', '.join(lda_cols)}) found for derived features.\")\n",
    "\n",
    "print(\"Derived features created.\")\n",
    "\n",
    "\n",
    "\n",
    "# 2) 간단 전처리 (전체 데이터 기준)\n",
    "# num_cols를 파생변수 생성 *후*에 정의하여 새로운 수치형 파생변수도 포함하도록 함\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = ['data_channel', 'weekday'] # These are the names of your categorical columns\n",
    "\n",
    "# --- 수치형: median 으로 결측 채우기\n",
    "X[num_cols] = X[num_cols].fillna(X[num_cols].median())\n",
    "# --- 범주형: 'missing' 문자열로 결측 채우기 (중요!)\n",
    "X[cat_cols] = X[cat_cols].fillna('missing')\n",
    "\n",
    "\n",
    "# 3) train/test 분할\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nData shapes after split: TrainVal({X_trainval.shape[0]}), Test({X_test.shape[0]})\")\n",
    "\n",
    "\n",
    "# 4) 하이퍼파라미터 탐색 범위 정의 (Tuned)\n",
    "param_dist_tuned = {\n",
    "    'learning_rate':        [0.01, 0.03, 0.05, 0.07, 0.1],\n",
    "    'depth':                [4, 6, 8, 10],\n",
    "    'l2_leaf_reg':          [1, 3, 5, 7, 9, 12],\n",
    "    'border_count':         [32, 64, 128, 254],\n",
    "    'bagging_temperature':  [0, 0.5, 1.0, 1.5, 2.0],\n",
    "    'random_strength':      [0.1, 0.5, 1, 2, 5],\n",
    "    'colsample_bylevel':    [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# 5) RandomizedSearchCV 세팅\n",
    "N_ITER_SEARCH = 30 # Increased from 20, adjust based on available time/resources\n",
    "\n",
    "base_model = CatBoostClassifier(\n",
    "    iterations=1000, # Max iterations for models during the search phase\n",
    "    random_state=42,\n",
    "    verbose=0, # Suppress output during RandomizedSearchCV's internal fits\n",
    "    task_type='CPU' \n",
    ")\n",
    "\n",
    "min_class_count = y_trainval.value_counts().min()\n",
    "n_cv_splits = 5\n",
    "if min_class_count < n_cv_splits:\n",
    "    print(f\"Warning: The smallest class in y_trainval has only {min_class_count} members, \"\n",
    "          f\"which is less than n_splits={n_cv_splits} for StratifiedKFold. \"\n",
    "          f\"Consider reducing n_splits or using a different CV strategy if issues arise.\")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=n_cv_splits, shuffle=True, random_state=42)\n",
    "\n",
    "print(f\"\\nStarting RandomizedSearchCV ({N_ITER_SEARCH} iterations) using CPU...\")\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=base_model,\n",
    "    param_distributions=param_dist_tuned,\n",
    "    n_iter=N_ITER_SEARCH,\n",
    "    scoring='roc_auc', # Focus on ROC AUC for optimization\n",
    "    cv=cv,\n",
    "    n_jobs=-1, \n",
    "    random_state=42,\n",
    "    verbose=1, # Show progress for RandomizedSearchCV\n",
    "    refit=True # Refit the best estimator on the whole X_trainval after search\n",
    ")\n",
    "\n",
    "# 6) CV 단계에서 cat_features만 전달\n",
    "search.fit(\n",
    "    X_trainval,\n",
    "    y_trainval,\n",
    "    cat_features=cat_cols\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RandomizedSearchCV Results:\")\n",
    "print(\"=\"*50)\n",
    "print(\"Best tuned hyperparameters found:\", search.best_params_)\n",
    "print(f\"Best CV ROC AUC score from RandomizedSearchCV: {search.best_score_:.4f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "\n",
    "# 7) 최종 모델에 early stopping + eval_set 걸어 재학습\n",
    "best_tuned_params = search.best_params_\n",
    "print(\"\\nParameters for Final Model Training:\", best_tuned_params)\n",
    "\n",
    "print(\"\\nTraining final tuned model with early stopping on test set using CPU...\")\n",
    "final_model_tuned_with_derived = CatBoostClassifier(\n",
    "    iterations=2000, # Allow more iterations; early stopping will find the optimum\n",
    "    learning_rate=best_tuned_params['learning_rate'],\n",
    "    depth=best_tuned_params['depth'],\n",
    "    l2_leaf_reg=best_tuned_params['l2_leaf_reg'],\n",
    "    border_count=best_tuned_params['border_count'],\n",
    "    bagging_temperature=best_tuned_params['bagging_temperature'],\n",
    "    random_strength=best_tuned_params['random_strength'],\n",
    "    colsample_bylevel=best_tuned_params['colsample_bylevel'],\n",
    "    eval_metric='AUC',\n",
    "    early_stopping_rounds=50,\n",
    "    use_best_model=True,\n",
    "    random_state=42,\n",
    "    verbose=100, \n",
    "    task_type='CPU' \n",
    ")\n",
    "\n",
    "final_model_tuned_with_derived.fit(\n",
    "    X_trainval,\n",
    "    y_trainval,\n",
    "    cat_features=cat_cols,\n",
    "    eval_set=[(X_test, y_test)] # Use X_test, y_test for early stopping (as in original code)\n",
    ")\n",
    "\n",
    "print(f\"\\nBest iteration found by early stopping for the final model: {final_model_tuned_with_derived.get_best_iteration()}\")\n",
    "\n",
    "\n",
    "# 8) Feature Importance Analysis\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Feature Importance Analysis:\")\n",
    "print(\"=\"*50)\n",
    "try:\n",
    "    feature_importances = final_model_tuned_with_derived.get_feature_importance(prettified=True)\n",
    "    print(\"\\nTop 20 Feature Importances:\")\n",
    "    print(feature_importances.head(20))\n",
    "\n",
    "    feature_importances.to_csv(\"feature_importances_with_derived_cpu_original_params.csv\", index=False)\n",
    "    print(\"\\nFeature importances saved to 'feature_importances_with_derived_cpu_original_params.csv'\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Could not retrieve feature importance: {e}\")\n",
    "\n",
    "print(\"\\nConsider reviewing feature importances. Low importance features might be removed,\")\n",
    "print(\"and high importance features could inspire new derived features in the next iteration.\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "\n",
    "# 9) Hold-out Test 성능 평가\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Tuned Model with Derived Features - FINAL HOLD-OUT TEST PERFORMANCE (CPU-trained):\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "y_pred_test = final_model_tuned_with_derived.predict(X_test)\n",
    "y_prob_test = final_model_tuned_with_derived.predict_proba(X_test)[:, 1]\n",
    "\n",
    "acc_test = accuracy_score(y_test, y_pred_test)\n",
    "f1_test  = f1_score(y_test, y_pred_test)\n",
    "auc_test = roc_auc_score(y_test, y_prob_test)\n",
    "\n",
    "# Composite score as defined in your original code\n",
    "comp_test = (acc_test + f1_test + auc_test) / 3\n",
    "\n",
    "print(f\"Accuracy : {acc_test:.4f}\")\n",
    "print(f\"F1 Score : {f1_test:.4f}\")\n",
    "print(f\"ROC AUC  : {auc_test:.4f}\")\n",
    "print(f\"Composite : {comp_test:.4f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "\n",
    "# 10) Save the trained model\n",
    "print(f\"\\nSaving the trained model to '{MODEL_FILE_PATH}'...\")\n",
    "try:\n",
    "    final_model_tuned_with_derived.save_model(MODEL_FILE_PATH)\n",
    "    print(\"Model saved successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving model: {e}\")\n",
    "\n",
    "\n",
    "# Calculate and print total execution time\n",
    "end_time = time.time()\n",
    "total_time_seconds = end_time - start_time\n",
    "hours = int(total_time_seconds // 3600)\n",
    "minutes = int((total_time_seconds % 3600) // 60)\n",
    "seconds = int(total_time_seconds % 60)\n",
    "\n",
    "print(f\"\\nTotal script execution time: {hours}h {minutes}m {seconds}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for trained model file at 'catboost_final_model_cpu.cbm'...\n",
      "Loading trained model from 'catboost_final_model_cpu.cbm'...\n",
      "Model loaded successfully.\n",
      "\n",
      "Loading test data from 'test.csv'...\n",
      "Test data loaded successfully.\n",
      "Creating derived features for test data (must match training)...\n",
      "Derived features created for test data.\n",
      "Applying preprocessing to test data (must match training)...\n",
      "Preprocessing applied to test data.\n",
      "\n",
      "Ensuring test data columns match the trained model's 53 features...\n",
      "Test data column order matches training data.\n",
      "\n",
      "Making predictions on the test data using CPU...\n",
      "Predictions completed.\n",
      "Creating prediction file 'prediction.csv' with id, y_predict, y_prob...\n",
      "\n",
      "Prediction file 'prediction.csv' created successfully.\n",
      "Predictions saved for 9515 rows.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "import os\n",
    "\n",
    "# Define the path to the saved model file and the submission file\n",
    "MODEL_FILE_PATH = 'catboost_final_model_cpu.cbm' \n",
    "SUBMISSION_FILE_PATH = 'prediction.csv'         \n",
    "TEST_DATA_PATH = 'test.csv' \n",
    "\n",
    "\n",
    "print(f\"Looking for trained model file at '{MODEL_FILE_PATH}'...\")\n",
    "if not os.path.exists(MODEL_FILE_PATH):\n",
    "    print(f\"Error: Trained model file not found at '{MODEL_FILE_PATH}'.\")\n",
    "    print(\"Please run the training script ('train_cpu_save.py') first to train and save the model.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Loading trained model from '{MODEL_FILE_PATH}'...\")\n",
    "# Create an empty CatBoostClassifier object and load the model into it.\n",
    "# Explicitly specify task_type='CPU' for prediction on CPU.\n",
    "model = CatBoostClassifier(task_type='CPU')\n",
    "try:\n",
    "    model.load_model(MODEL_FILE_PATH)\n",
    "    print(\"Model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# 1) Load the test data\n",
    "print(f\"\\nLoading test data from '{TEST_DATA_PATH}'...\")\n",
    "try:\n",
    "    df_test = pd.read_csv(TEST_DATA_PATH)\n",
    "    print(\"Test data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: '{TEST_DATA_PATH}' not found.\")\n",
    "    exit()\n",
    "\n",
    "# Store the original IDs for the submission file\n",
    "test_ids = df_test['id']\n",
    "\n",
    "# Drop the id column from the features\n",
    "X_test = df_test.drop(columns=['id'])\n",
    "\n",
    "\n",
    "# *** Apply the SAME Derived Feature Creation as in the training script ***\n",
    "print(\"Creating derived features for test data (must match training)...\")\n",
    "epsilon = 1e-6 # Prevent division by zero (same as training)\n",
    "\n",
    "if 'n_tokens_content' in X_test.columns and 'num_hrefs' in X_test.columns:\n",
    "    X_test['feat_content_to_href_ratio'] = X_test['n_tokens_content'] / (X_test['num_hrefs'] + epsilon)\n",
    "else:\n",
    "    print(\"Warning: Columns for 'feat_content_to_href_ratio' not found in test data.\")\n",
    "\n",
    "if 'n_tokens_content' in X_test.columns and 'num_imgs' in X_test.columns:\n",
    "    X_test['feat_content_to_img_ratio'] = X_test['n_tokens_content'] / (X_test['num_imgs'] + epsilon)\n",
    "else:\n",
    "    print(\"Warning: Columns for 'feat_content_to_img_ratio' not found in test data.\")\n",
    "\n",
    "if 'kw_avg_max' in X_test.columns and 'kw_avg_min' in X_test.columns:\n",
    "    X_test['feat_kw_avg_spread'] = X_test['kw_avg_max'] - X_test['kw_avg_min']\n",
    "else:\n",
    "    print(\"Warning: Columns for 'feat_kw_avg_spread' not found in test data.\")\n",
    "\n",
    "if 'global_subjectivity' in X_test.columns and 'global_sentiment_polarity' in X_test.columns:\n",
    "    X_test['feat_global_sentiment_strength'] = X_test['global_subjectivity'] * X_test['global_sentiment_polarity']\n",
    "else:\n",
    "    print(\"Warning: Columns for 'feat_global_sentiment_strength' not found in test data.\")\n",
    "\n",
    "if 'title_subjectivity' in X_test.columns and 'title_sentiment_polarity' in X_test.columns:\n",
    "    X_test['feat_title_sentiment_strength'] = X_test['title_subjectivity'] * X_test['title_sentiment_polarity']\n",
    "else:\n",
    "    print(\"Warning: Columns for 'feat_title_sentiment_strength' not found in test data.\")\n",
    "\n",
    "lda_cols = ['LDA_00', 'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04']\n",
    "if all(col in X_test.columns for col in lda_cols):\n",
    "    X_test['feat_lda_max_value'] = X_test[lda_cols].max(axis=1)\n",
    "    X_test['feat_lda_std_dev'] = X_test[lda_cols].std(axis=1)\n",
    "else:\n",
    "    print(f\"Warning: Not all LDA columns ({', '.join(lda_cols)}) found for derived features in test data.\")\n",
    "\n",
    "print(\"Derived features created for test data.\")\n",
    "\n",
    "\n",
    "# *** Apply the SAME Preprocessing (Missing Value Imputation) ***\n",
    "print(\"Applying preprocessing to test data (must match training)...\")\n",
    "\n",
    "num_cols_test = X_test.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols_test = ['data_channel', 'weekday']\n",
    "\n",
    "# --- Numeric: Fill missing with median of the test set (Simplification) ---\n",
    "X_test[num_cols_test] = X_test[num_cols_test].fillna(X_test[num_cols_test].median())\n",
    "# --- Categorical: Fill missing with 'missing' string (same as training) ---\n",
    "X_test[cat_cols_test] = X_test[cat_cols_test].fillna('missing')\n",
    "\n",
    "print(\"Preprocessing applied to test data.\")\n",
    "\n",
    "\n",
    "# --- Ensure Column Order Matches Trained Model ---\n",
    "train_features_order = model.feature_names_\n",
    "print(f\"\\nEnsuring test data columns match the trained model's {len(train_features_order)} features...\")\n",
    "\n",
    "try:\n",
    "    X_test = X_test[train_features_order]\n",
    "    print(\"Test data column order matches training data.\")\n",
    "except KeyError as e:\n",
    "    print(f\"Error: Column mismatch between test data and trained model features: {e}\")\n",
    "    print(\"Please ensure test data has all necessary features created during training.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# 5) Make predictions on the processed test data\n",
    "print(\"\\nMaking predictions on the test data using CPU...\")\n",
    "\n",
    "# Predict binary classes (0 or 1)\n",
    "test_predictions_binary = model.predict(X_test)\n",
    "\n",
    "# Predict probabilities for the positive class (assuming 1 is the positive class).\n",
    "# predict_proba returns shape (n_samples, n_classes). We need the second column (index 1).\n",
    "test_probabilities = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Predictions completed.\")\n",
    "\n",
    "\n",
    "# 6) Create submission file with id, y_predict, and y_prob\n",
    "print(f\"Creating prediction file '{SUBMISSION_FILE_PATH}' with id, y_predict, y_prob...\")\n",
    "prediction_df = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'y_predict': test_predictions_binary,\n",
    "    'y_prob': test_probabilities\n",
    "})\n",
    "\n",
    "# Save the prediction file\n",
    "prediction_df.to_csv(SUBMISSION_FILE_PATH, index=False)\n",
    "\n",
    "print(f\"\\nPrediction file '{SUBMISSION_FILE_PATH}' created successfully.\")\n",
    "print(f\"Predictions saved for {len(prediction_df)} rows.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
