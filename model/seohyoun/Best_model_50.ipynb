{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNJv/AEBzSxKmw2okRXtyfT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["! pip install feature_engine\n","! pip install CatBoost\n","! pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BaTFriqa5oqh","executionInfo":{"status":"ok","timestamp":1747447097127,"user_tz":-540,"elapsed":38622,"user":{"displayName":"김서현","userId":"08818282308943516715"}},"outputId":"42ba8ea1-9fa9-484f-8f88-84a9b49913b1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting feature_engine\n","  Downloading feature_engine-1.8.3-py2.py3-none-any.whl.metadata (9.9 kB)\n","Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.11/dist-packages (from feature_engine) (2.0.2)\n","Requirement already satisfied: pandas>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from feature_engine) (2.2.2)\n","Requirement already satisfied: scikit-learn>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from feature_engine) (1.6.1)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from feature_engine) (1.15.3)\n","Requirement already satisfied: statsmodels>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from feature_engine) (0.14.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->feature_engine) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->feature_engine) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->feature_engine) (2025.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.0->feature_engine) (1.5.0)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.0->feature_engine) (3.6.0)\n","Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.11.1->feature_engine) (1.0.1)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.11.1->feature_engine) (24.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2.0->feature_engine) (1.17.0)\n","Downloading feature_engine-1.8.3-py2.py3-none-any.whl (378 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.6/378.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: feature_engine\n","Successfully installed feature_engine-1.8.3\n","Collecting CatBoost\n","  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from CatBoost) (0.20.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from CatBoost) (3.10.0)\n","Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from CatBoost) (2.0.2)\n","Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from CatBoost) (2.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from CatBoost) (1.15.3)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from CatBoost) (5.24.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from CatBoost) (1.17.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->CatBoost) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->CatBoost) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->CatBoost) (2025.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->CatBoost) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->CatBoost) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->CatBoost) (4.58.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->CatBoost) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->CatBoost) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->CatBoost) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->CatBoost) (3.2.3)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->CatBoost) (9.1.2)\n","Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: CatBoost\n","Successfully installed CatBoost-1.2.8\n","Collecting optuna\n","  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n","Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Installing collected packages: colorlog, alembic, optuna\n","Successfully installed alembic-1.15.2 colorlog-6.9.0 optuna-4.3.0\n"]}]},{"cell_type":"code","source":["# 데이터 불러오기\n","from google.colab import drive\n","drive.mount('/content/drive')\n","train_src = '/content/drive/MyDrive/Colab Notebooks/패턴인식/train.csv'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S-r5IGrP5s3-","executionInfo":{"status":"ok","timestamp":1747447191638,"user_tz":-540,"elapsed":29561,"user":{"displayName":"김서현","userId":"08818282308943516715"}},"outputId":"70b1b739-8b36-4a60-e7d0-8545902ae20b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# ── ② 파생 변수 생성 ──                                                                           # df 통계형 변수를 쓸 때는 데이터 누수 주의\n","\n","def create_features(df):\n","    # 1) 제목 길이 대비 본문 길이 비율\n","    df['title_content_ratio'] = df['n_tokens_title'] / df['n_tokens_content'].replace(0, np.nan)\n","\n","    # 2) 키워드 밀도: 전체 토큰 대비 키워드 개수 비율\n","    df['keyword_density']    = df['num_keywords'] / df['n_tokens_content'].replace(0, np.nan)\n","\n","    # 3) 비중어(non-stop) 단어 비율: 본문 대비\n","    df['nonstop_ratio']      = df['n_non_stop_words'] / df['n_tokens_content'].replace(0, np.nan)\n","\n","    # 4) 본문 내 링크 대비 자기링크 비율\n","    df['self_href_ratio']    = df['num_self_hrefs'] / df['num_hrefs'].replace(0, np.nan)\n","\n","    # 5) 이미지/동영상 비율\n","    df['img_video_ratio']    = df['num_imgs'] / (df['num_videos'] + 1)\n","\n","    # 6) 키워드 분포 폭: (최댓값 키워드 빈도 – 최솟값 키워드 빈도)\n","    df['kw_spread']          = df['kw_max_max'] - df['kw_min_min']\n","\n","    # 7) 감성 범위: (최대 양성 편향 – 최소 음성 편향)\n","    df['sentiment_range']    = df['max_positive_polarity'] - df['min_negative_polarity']\n","\n","    # 8) 제목 감성 상호작용: 주관성 × 편향 절대값\n","    df['title_sent_interact']= df['abs_title_subjectivity'] * df['abs_title_sentiment_polarity']\n","\n","    # 9) 주말 여부 플래그\n","    df['is_weekend']         = df['weekday'].isin(['Saturday','Sunday']).astype(int)\n","\n","    # 10) 채널×주말 교차 카테고리 (필요시 one-hot 인코딩)\n","    df['channel_weekend']    = df['data_channel'] + '_' + df['is_weekend'].astype(str)\n","\n","    return df\n"],"metadata":{"id":"IzrifFPNpLTl","executionInfo":{"status":"ok","timestamp":1747447191663,"user_tz":-540,"elapsed":6,"user":{"displayName":"김서현","userId":"08818282308943516715"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"id":"0QXfJ62f5fnV","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1747452432005,"user_tz":-540,"elapsed":4722295,"user":{"displayName":"김서현","userId":"08818282308943516715"}},"outputId":"f1f4df5b-78af-49d3-cc24-0cd8e511a3f6"},"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2025-05-17 02:09:20,215] A new study created in memory with name: no-name-0575cab3-19b0-4d94-a3ed-84d9856fae86\n"]},{"output_type":"stream","name":"stdout","text":["▶ 선택된 피처: ['n_unique_tokens', 'n_non_stop_unique_tokens', 'average_token_length', 'kw_max_min', 'kw_avg_min', 'kw_avg_max', 'kw_min_avg', 'kw_max_avg', 'kw_avg_avg', 'self_reference_min_shares', 'self_reference_max_shares', 'self_reference_avg_sharess', 'LDA_00', 'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04', 'global_subjectivity', 'global_rate_positive_words', 'global_rate_negative_words', 'avg_positive_polarity', 'title_content_ratio', 'keyword_density', 'self_href_ratio', 'img_video_ratio', 'data_channel', 'weekday', 'channel_weekend']\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-05-17 02:13:46,634] Trial 0 finished with value: 0.7099063220431535 and parameters: {'depth': 10, 'learning_rate': 0.010482260789173897, 'l2_leaf_reg': 0.1455509331160738, 'iterations': 619}. Best is trial 0 with value: 0.7099063220431535.\n","[I 2025-05-17 02:13:57,189] Trial 1 finished with value: 0.6826745487358922 and parameters: {'depth': 4, 'learning_rate': 0.005378646586870534, 'l2_leaf_reg': 0.35295055322652047, 'iterations': 230}. Best is trial 0 with value: 0.7099063220431535.\n","[I 2025-05-17 02:17:13,223] Trial 2 finished with value: 0.6990700109520475 and parameters: {'depth': 10, 'learning_rate': 0.07243259768948074, 'l2_leaf_reg': 0.7106464878254433, 'iterations': 449}. Best is trial 0 with value: 0.7099063220431535.\n","[I 2025-05-17 02:18:17,323] Trial 3 finished with value: 0.6933368723158658 and parameters: {'depth': 7, 'learning_rate': 0.001959105214477111, 'l2_leaf_reg': 2.528578799269137, 'iterations': 590}. Best is trial 0 with value: 0.7099063220431535.\n","[I 2025-05-17 02:20:14,449] Trial 4 finished with value: 0.7051776459512862 and parameters: {'depth': 8, 'learning_rate': 0.004280125570961514, 'l2_leaf_reg': 3.495820355297714, 'iterations': 699}. Best is trial 0 with value: 0.7099063220431535.\n","[I 2025-05-17 02:23:19,325] Trial 5 finished with value: 0.7029545974063985 and parameters: {'depth': 9, 'learning_rate': 0.002690892553032814, 'l2_leaf_reg': 0.23421169934846123, 'iterations': 663}. Best is trial 0 with value: 0.7099063220431535.\n","[I 2025-05-17 02:27:12,851] Trial 6 finished with value: 0.701069945017344 and parameters: {'depth': 9, 'learning_rate': 0.001865828074690242, 'l2_leaf_reg': 0.5633115331728187, 'iterations': 804}. Best is trial 0 with value: 0.7099063220431535.\n","[I 2025-05-17 02:28:05,503] Trial 7 finished with value: 0.7113348988403052 and parameters: {'depth': 6, 'learning_rate': 0.015308306638376906, 'l2_leaf_reg': 1.3418541124280778, 'iterations': 641}. Best is trial 7 with value: 0.7113348988403052.\n","[I 2025-05-17 02:28:31,498] Trial 8 finished with value: 0.6926318107390604 and parameters: {'depth': 5, 'learning_rate': 0.004389055806462067, 'l2_leaf_reg': 0.4032797888500006, 'iterations': 450}. Best is trial 7 with value: 0.7113348988403052.\n","[I 2025-05-17 02:29:57,870] Trial 9 finished with value: 0.713445058917238 and parameters: {'depth': 7, 'learning_rate': 0.013175557036821436, 'l2_leaf_reg': 0.4540825019349995, 'iterations': 778}. Best is trial 9 with value: 0.713445058917238.\n","[I 2025-05-17 02:31:48,355] Trial 10 finished with value: 0.709909938151175 and parameters: {'depth': 7, 'learning_rate': 0.032437948110239014, 'l2_leaf_reg': 9.015288342359854, 'iterations': 984}. Best is trial 9 with value: 0.713445058917238.\n","[I 2025-05-17 02:32:59,842] Trial 11 finished with value: 0.713758610349902 and parameters: {'depth': 6, 'learning_rate': 0.016421829735607976, 'l2_leaf_reg': 1.5836989831075927, 'iterations': 875}. Best is trial 11 with value: 0.713758610349902.\n","[I 2025-05-17 02:34:15,906] Trial 12 finished with value: 0.7125692401019794 and parameters: {'depth': 6, 'learning_rate': 0.02239553657580818, 'l2_leaf_reg': 1.5103007605101904, 'iterations': 931}. Best is trial 11 with value: 0.713758610349902.\n","[I 2025-05-17 02:35:36,970] Trial 13 finished with value: 0.708491406938251 and parameters: {'depth': 6, 'learning_rate': 0.04770680273049132, 'l2_leaf_reg': 4.100400131157065, 'iterations': 849}. Best is trial 11 with value: 0.713758610349902.\n","[I 2025-05-17 02:36:15,772] Trial 14 finished with value: 0.7048699544344865 and parameters: {'depth': 4, 'learning_rate': 0.009278936131672627, 'l2_leaf_reg': 0.988170538646985, 'iterations': 823}. Best is trial 11 with value: 0.713758610349902.\n","[I 2025-05-17 02:38:21,390] Trial 15 finished with value: 0.7128253002315196 and parameters: {'depth': 8, 'learning_rate': 0.019121149846670266, 'l2_leaf_reg': 1.9339187708632544, 'iterations': 749}. Best is trial 11 with value: 0.713758610349902.\n","[I 2025-05-17 02:39:16,890] Trial 16 finished with value: 0.7080027991333067 and parameters: {'depth': 5, 'learning_rate': 0.009052505885746825, 'l2_leaf_reg': 0.19585752169732754, 'iterations': 908}. Best is trial 11 with value: 0.713758610349902.\n","[I 2025-05-17 02:40:11,201] Trial 17 finished with value: 0.7057466103854555 and parameters: {'depth': 7, 'learning_rate': 0.037320165731095596, 'l2_leaf_reg': 0.10049107167856225, 'iterations': 487}. Best is trial 11 with value: 0.713758610349902.\n","[I 2025-05-17 02:41:15,326] Trial 18 finished with value: 0.701214068694514 and parameters: {'depth': 5, 'learning_rate': 0.09350588230810253, 'l2_leaf_reg': 6.485815210617422, 'iterations': 990}. Best is trial 11 with value: 0.713758610349902.\n","[I 2025-05-17 02:43:17,739] Trial 19 finished with value: 0.7131760604141965 and parameters: {'depth': 8, 'learning_rate': 0.01320846338705268, 'l2_leaf_reg': 0.869959142935816, 'iterations': 748}. Best is trial 11 with value: 0.713758610349902.\n","[I 2025-05-17 02:43:33,784] Trial 20 finished with value: 0.6826180060425605 and parameters: {'depth': 6, 'learning_rate': 0.0011611180236886706, 'l2_leaf_reg': 0.4411100122649556, 'iterations': 201}. Best is trial 11 with value: 0.713758610349902.\n","[I 2025-05-17 02:45:42,064] Trial 21 finished with value: 0.713104188681959 and parameters: {'depth': 8, 'learning_rate': 0.011041984454317071, 'l2_leaf_reg': 0.89724726409656, 'iterations': 779}. Best is trial 11 with value: 0.713758610349902.\n","[I 2025-05-17 02:48:08,034] Trial 22 finished with value: 0.7099300606042883 and parameters: {'depth': 8, 'learning_rate': 0.025570087278062037, 'l2_leaf_reg': 0.6425387281234312, 'iterations': 882}. Best is trial 11 with value: 0.713758610349902.\n","[I 2025-05-17 02:51:27,852] Trial 23 finished with value: 0.7118837702357896 and parameters: {'depth': 9, 'learning_rate': 0.01502191356707765, 'l2_leaf_reg': 1.132822383100968, 'iterations': 708}. Best is trial 11 with value: 0.713758610349902.\n","[I 2025-05-17 02:52:26,057] Trial 24 finished with value: 0.7054017093817584 and parameters: {'depth': 7, 'learning_rate': 0.0067908427247850445, 'l2_leaf_reg': 0.26927456701061836, 'iterations': 527}. Best is trial 11 with value: 0.713758610349902.\n","[I 2025-05-17 02:54:31,490] Trial 25 finished with value: 0.712890055763812 and parameters: {'depth': 8, 'learning_rate': 0.01471779596308872, 'l2_leaf_reg': 2.1221631047082132, 'iterations': 763}. Best is trial 11 with value: 0.713758610349902.\n","[I 2025-05-17 02:55:40,390] Trial 26 finished with value: 0.7079994880009863 and parameters: {'depth': 6, 'learning_rate': 0.006727267843006306, 'l2_leaf_reg': 0.8377609341551769, 'iterations': 857}. Best is trial 11 with value: 0.713758610349902.\n","[I 2025-05-17 02:56:18,945] Trial 27 finished with value: 0.7080707513251364 and parameters: {'depth': 7, 'learning_rate': 0.048359004352196464, 'l2_leaf_reg': 0.5221723487165844, 'iterations': 340}. Best is trial 11 with value: 0.713758610349902.\n","[I 2025-05-17 02:58:03,346] Trial 28 finished with value: 0.7131761735609418 and parameters: {'depth': 7, 'learning_rate': 0.02583856846336625, 'l2_leaf_reg': 3.094353426875538, 'iterations': 936}. Best is trial 11 with value: 0.713758610349902.\n","[I 2025-05-17 02:59:03,661] Trial 29 finished with value: 0.7126066825143269 and parameters: {'depth': 5, 'learning_rate': 0.029815324004448744, 'l2_leaf_reg': 3.4541134181297544, 'iterations': 943}. Best is trial 11 with value: 0.713758610349902.\n","[I 2025-05-17 03:00:21,699] Trial 30 finished with value: 0.7139316863917715 and parameters: {'depth': 6, 'learning_rate': 0.019604014878239595, 'l2_leaf_reg': 5.172061804107547, 'iterations': 940}. Best is trial 30 with value: 0.7139316863917715.\n","[I 2025-05-17 03:01:38,275] Trial 31 finished with value: 0.7137694540196566 and parameters: {'depth': 6, 'learning_rate': 0.018139601986308596, 'l2_leaf_reg': 5.330590729138109, 'iterations': 946}. Best is trial 30 with value: 0.7139316863917715.\n","[I 2025-05-17 03:02:51,470] Trial 32 finished with value: 0.7149144214772792 and parameters: {'depth': 6, 'learning_rate': 0.01887143254640496, 'l2_leaf_reg': 5.612912910084233, 'iterations': 897}. Best is trial 32 with value: 0.7149144214772792.\n","[I 2025-05-17 03:04:03,848] Trial 33 finished with value: 0.7127113838219428 and parameters: {'depth': 6, 'learning_rate': 0.019286164896713292, 'l2_leaf_reg': 4.883400303984895, 'iterations': 884}. Best is trial 32 with value: 0.7149144214772792.\n","[I 2025-05-17 03:04:54,076] Trial 34 finished with value: 0.709495256824602 and parameters: {'depth': 4, 'learning_rate': 0.04436134984694682, 'l2_leaf_reg': 6.158861442681265, 'iterations': 988}. Best is trial 32 with value: 0.7149144214772792.\n","[I 2025-05-17 03:05:47,317] Trial 35 finished with value: 0.7122324040920746 and parameters: {'depth': 5, 'learning_rate': 0.019363537013005444, 'l2_leaf_reg': 9.555069075458718, 'iterations': 837}. Best is trial 32 with value: 0.7149144214772792.\n","[I 2025-05-17 03:06:35,206] Trial 36 finished with value: 0.7076991780295773 and parameters: {'depth': 6, 'learning_rate': 0.06929419862251157, 'l2_leaf_reg': 6.446038357429165, 'iterations': 586}. Best is trial 32 with value: 0.7149144214772792.\n","[I 2025-05-17 03:06:57,576] Trial 37 finished with value: 0.7005375454058491 and parameters: {'depth': 5, 'learning_rate': 0.010535430117050375, 'l2_leaf_reg': 2.6545688276022408, 'iterations': 344}. Best is trial 32 with value: 0.7149144214772792.\n","[I 2025-05-17 03:08:14,121] Trial 38 finished with value: 0.7133837247448236 and parameters: {'depth': 6, 'learning_rate': 0.01889411239200195, 'l2_leaf_reg': 4.80708871341292, 'iterations': 940}. Best is trial 32 with value: 0.7149144214772792.\n","[I 2025-05-17 03:09:27,419] Trial 39 finished with value: 0.7070351710738771 and parameters: {'depth': 6, 'learning_rate': 0.0062566508628435075, 'l2_leaf_reg': 7.658399116624044, 'iterations': 892}. Best is trial 32 with value: 0.7149144214772792.\n","[I 2025-05-17 03:10:04,691] Trial 40 finished with value: 0.7090663051212777 and parameters: {'depth': 4, 'learning_rate': 0.05995510148435852, 'l2_leaf_reg': 5.070665792884728, 'iterations': 706}. Best is trial 32 with value: 0.7149144214772792.\n","[I 2025-05-17 03:11:33,101] Trial 41 finished with value: 0.712162700368554 and parameters: {'depth': 7, 'learning_rate': 0.012661787415596036, 'l2_leaf_reg': 0.31791367435984447, 'iterations': 800}. Best is trial 32 with value: 0.7149144214772792.\n","[I 2025-05-17 03:12:50,345] Trial 42 finished with value: 0.7107289145517166 and parameters: {'depth': 6, 'learning_rate': 0.02477935011693573, 'l2_leaf_reg': 2.0919693518031184, 'iterations': 952}. Best is trial 32 with value: 0.7149144214772792.\n","[I 2025-05-17 03:14:29,338] Trial 43 finished with value: 0.7101949913306091 and parameters: {'depth': 7, 'learning_rate': 0.03428064574173828, 'l2_leaf_reg': 1.5236530852913832, 'iterations': 876}. Best is trial 32 with value: 0.7149144214772792.\n","[I 2025-05-17 03:21:41,569] Trial 44 finished with value: 0.7114910793776764 and parameters: {'depth': 10, 'learning_rate': 0.00788182009282988, 'l2_leaf_reg': 4.139883094637172, 'iterations': 999}. Best is trial 32 with value: 0.7149144214772792.\n","[I 2025-05-17 03:23:13,152] Trial 45 finished with value: 0.7061970952235891 and parameters: {'depth': 7, 'learning_rate': 0.004740196837841724, 'l2_leaf_reg': 7.917695527583087, 'iterations': 833}. Best is trial 32 with value: 0.7149144214772792.\n","[I 2025-05-17 03:24:27,074] Trial 46 finished with value: 0.7133355204021056 and parameters: {'depth': 6, 'learning_rate': 0.015539188990521086, 'l2_leaf_reg': 3.170088211745366, 'iterations': 910}. Best is trial 32 with value: 0.7149144214772792.\n","[I 2025-05-17 03:25:28,484] Trial 47 finished with value: 0.71217171886964 and parameters: {'depth': 5, 'learning_rate': 0.017148664006929604, 'l2_leaf_reg': 3.981420659031642, 'iterations': 963}. Best is trial 32 with value: 0.7149144214772792.\n","[I 2025-05-17 03:26:23,591] Trial 48 finished with value: 0.7107801248333327 and parameters: {'depth': 6, 'learning_rate': 0.011910809326386992, 'l2_leaf_reg': 2.43793499889359, 'iterations': 673}. Best is trial 32 with value: 0.7149144214772792.\n","[I 2025-05-17 03:27:11,845] Trial 49 finished with value: 0.6972998414363144 and parameters: {'depth': 5, 'learning_rate': 0.0036216070781349497, 'l2_leaf_reg': 0.1732918432517504, 'iterations': 797}. Best is trial 32 with value: 0.7149144214772792.\n"]},{"output_type":"stream","name":"stdout","text":["▶ Best params: {'depth': 6, 'learning_rate': 0.01887143254640496, 'l2_leaf_reg': 5.612912910084233, 'iterations': 897}\n","▶ Best 3-fold CV ROC AUC: 0.7149144214772792\n"]},{"output_type":"error","ename":"SyntaxError","evalue":"keyword argument repeated: thread_count (<ipython-input-6-7b63e49c261c>, line 129)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-7b63e49c261c>\"\u001b[0;36m, line \u001b[0;32m129\u001b[0m\n\u001b[0;31m    thread_count=1\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m keyword argument repeated: thread_count\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n","from sklearn.impute import SimpleImputer\n","from feature_engine.outliers import Winsorizer\n","from sklearn.feature_selection import SelectFromModel\n","from catboost import CatBoostClassifier\n","from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n","import optuna\n","from sklearn.model_selection import cross_val_score\n","\n","# 1) 데이터 로드 & train/holdout 분리\n","df = pd.read_csv(train_src)\n","\n","df = create_features(df)\n","\n","X  = df.drop(['id','shares','y'], axis=1)\n","y  = df['y']\n","X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n","\n","# 2) 컬럼 나누기\n","num_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()\n","cat_cols = ['data_channel','weekday','channel_weekend']  # ← 실제 범주형명 사용\n","\n","# 3) 수치형 전처리: median → Winsorizer\n","num_imputer = SimpleImputer(strategy='median')\n","winsorizer  = Winsorizer(capping_method='gaussian', tail='both', fold=3)  # ← fold 조절 가능\n","\n","X_tr_num = num_imputer.fit_transform( X_tr[num_cols] )\n","X_tr_num = winsorizer.fit_transform(pd.DataFrame(X_tr_num, columns=num_cols)).values\n","\n","X_te_num = num_imputer.transform( X_te[num_cols] )\n","X_te_num = winsorizer.transform(pd.DataFrame(X_te_num, columns=num_cols)).values\n","\n","# 4) 범주형 전처리: most_frequent → category\n","cat_imputer = SimpleImputer(strategy='most_frequent')\n","\n","X_tr_cat = pd.DataFrame(\n","    cat_imputer.fit_transform(X_tr[cat_cols]),\n","    columns=cat_cols, index=X_tr.index\n",").astype('category')\n","\n","X_te_cat = pd.DataFrame(\n","    cat_imputer.transform(X_te[cat_cols]),\n","    columns=cat_cols, index=X_te.index\n",").astype('category')\n","\n","# 5) 최종 학습용 DataFrame 합치기\n","X_tr_final = pd.concat([\n","    pd.DataFrame(X_tr_num, columns=num_cols, index=X_tr.index),\n","    X_tr_cat\n","], axis=1)\n","\n","X_te_final = pd.concat([\n","    pd.DataFrame(X_te_num, columns=num_cols, index=X_te.index),\n","    X_te_cat\n","], axis=1)\n","\n","# 6) SelectFromModel로 피처 선택\n","base_model = CatBoostClassifier(\n","    iterations=500,             # ← 이후 그리드/베이지안 탐색할 파라미터\n","    learning_rate=0.05,         # ← 여기부터 튜닝\n","    depth=6,\n","    eval_metric='AUC',\n","    random_seed=42,\n","    thread_count=1,\n","    verbose=False,\n","    cat_features=cat_cols\n",")\n","base_model.fit(X_tr_final, y_tr)\n","\n","selector = SelectFromModel(\n","    estimator=base_model,\n","    threshold='median'            # ← 'mean','median' 또는 float 값으로 바꿔가며 실험\n",")\n","selector.fit(X_tr_final, y_tr)\n","\n","selected_feats = X_tr_final.columns[ selector.get_support() ].tolist()\n","print(\"▶ 선택된 피처:\", selected_feats)\n","\n","X_tr_sel = X_tr_final[selected_feats]\n","X_te_sel = X_te_final[selected_feats]\n","\n","\n","# 7) Optuna로 하이퍼파라미터 최적화\n","inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n","\n","def objective(trial):\n","    # 7-1) 하이퍼파라미터 제안\n","    params = {\n","        'depth':          trial.suggest_int('depth', 4, 10),\n","        'learning_rate':  trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True),    # ← 변경\n","        'l2_leaf_reg':    trial.suggest_float('l2_leaf_reg',   0.1,   10,   log=True),    # ← 변경\n","        'iterations':     trial.suggest_int('iterations', 200, 1000),\n","        'random_seed':    42,\n","        'eval_metric':    'AUC',\n","        'verbose':        False,\n","    }\n","\n","    # 7-2) 모델 생성 & CV 평가\n","    model = CatBoostClassifier(**params, cat_features=cat_cols, thread_count=1)\n","    aucs = cross_val_score(\n","        model,\n","        X_tr_sel, y_tr,\n","        cv=inner_cv,\n","        scoring='roc_auc',\n","        n_jobs=-1\n","    )\n","    # 7-3) 평균 AUC 반환\n","    return aucs.mean()\n","\n","# 7-4) 스터디 생성 및 최적화 실행\n","study = optuna.create_study(direction='maximize')\n","study.optimize(objective, n_trials=50)\n","\n","# 7-5) 결과 출력\n","print(\"▶ Best params:\", study.best_trial.params)\n","print(\"▶ Best 3-fold CV ROC AUC:\", study.best_value)\n","\n","# 8) 최적 파라미터로 최종 모델 학습 & Holdout 평가\n","best_params = study.best_trial.params\n","best_model = CatBoostClassifier(\n","    **best_params,\n","    random_seed=42,\n","    thread_count=1,\n","    early_stopping_rounds = 30,\n","    verbose=False,\n","    cat_features=cat_cols,\n",")\n","best_model.fit(X_tr_sel, y_tr)\n","y_pred = best_model.predict(X_te_sel)\n","y_prob = best_model.predict_proba(X_te_sel)[:,1]\n","\n","acc  = accuracy_score(y_te, y_pred)\n","f1   = f1_score(y_te, y_pred)\n","auc  = roc_auc_score(y_te, y_prob)\n","comp = (acc + f1 + auc) / 3\n","\n","# 7-5) 결과 출력\n","best_params = study.best_trial.params\n","print(\"▶ Best params:\", best_params)\n","print(\"  - depth         :\", best_params['depth'])\n","print(\"  - learning_rate:\", best_params['learning_rate'])\n","print(\"  - l2_leaf_reg  :\", best_params['l2_leaf_reg'])\n","print(\"  - iterations   :\", best_params['iterations'])\n","print(\"▶ Best 3-fold CV ROC AUC:\", study.best_value)\n","\n","\n","print(\"\\n▶ Holdout Test Performance (best model)\")\n","print(f\"Accuracy : {acc:.4f}\")\n","print(f\"F1 Score : {f1:.4f}\")\n","print(f\"ROC AUC  : {auc:.4f}\")\n","print(f\"Composite: {comp:.4f}\")\n","\n","\n","# # 7) 최종 CatBoost 모델 학습 & 평가\n","# model = CatBoostClassifier(\n","#     iterations=1000,            # ← 최종 탐색 범위\n","#     learning_rate=0.05,\n","#     depth=4,\n","#     eval_metric='AUC',\n","#     random_seed=42,\n","#     thread_count=1,\n","#     early_stopping_rounds = 30,\n","#     verbose=False,\n","#     cat_features=[c for c in selected_feats if c in cat_cols]\n","# )\n","\n","# # 7-1) 5-Fold CV (train_val)\n","# cv      = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","# scoring = ['accuracy','f1','roc_auc']\n","# cv_res  = cross_validate(model, X_tr_sel, y_tr, cv=cv, scoring=scoring, error_score='raise')\n","\n","# acc  = cv_res['test_accuracy']\n","# f1   = cv_res['test_f1']\n","# auc  = cv_res['test_roc_auc']\n","# comp = (acc + f1 + auc) / 3\n","\n","# print(\"\\n5-Fold CV (train_val)\")\n","# for i,(a,f,u,c) in enumerate(zip(acc,f1,auc,comp), 1):\n","#     print(f\"[Fold {i}] Acc:{a:.4f}, F1:{f:.4f}, AUC:{u:.4f}, Comp:{c:.4f}\")\n","# print(\"평균 Composite:\", comp.mean())\n","\n","# # 7-2) Holdout Test\n","# model.fit(X_tr_sel, y_tr)\n","# y_pred = model.predict(X_te_sel)\n","# y_prob = model.predict_proba(X_te_sel)[:,1]\n","\n","# acc  = accuracy_score(y_te, y_pred)\n","# f1   = f1_score(y_te, y_pred)\n","# auc  = roc_auc_score(y_te, y_prob)\n","# comp = (acc + f1 + auc) / 3\n","\n","# print(\"\\nHoldout Test\")\n","# print(f\"Accuracy : {acc:.4f}\")\n","# print(f\"F1 Score : {f1:.4f}\")\n","# print(f\"ROC AUC  : {auc:.4f}\")\n","# print(f\"Composite: {comp:.4f}\")\n"]}]}